{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 250px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scénarios d'Apprentissage Statistique](https://github.com/wikistat/Apprentissage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exemple \"Jouet\": Discrimination de Mélanges Gaussiens avec <a href=\"https://cran.r-project.org/\"><img src=\"https://cran.r-project.org/Rlogo.svg\" style=\"max-width: 40px; display: inline\" alt=\"R\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résumé**: Les méthodes de [discrimination](http://wikistat.fr/pdf/st-m-app-intro.pdf) sont  comparées sur un jeu de données fictif obtenu par la simulation d'observations $(x_i, y_i), i=1\\ldots,n$ suivant 4 gaussiennes bidimensionnelles et séparées en 2 classes. L'objectif est de mettre en évidence le rôle des paramètres de complexité de différentes méthodes (régression logistique, k-nn, réseaux de neurones, arbre de décision, bagging, svm) et de comparer les formes spécifiques des frontières estimées par chacune d'elle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "Les données très rudimentaires ont été obtenues par la simulation de 4 gaussiennes bidimensionnelles ; 3 gaussiennes sont associées à une classe la 4ème à une autre classes. L'objectif est d'apprendre ces données très particulières afin de discriminer les deux classes. Les données étant simplement dans $\\boldsymbol{R}^2$, il est facile de prévoir la classe de chaque point du plan et ainsi de visualiser la frontière entre les prévisions des deux classes. L'intérêt est de représenter ainsi facilement le rôle jouer par les paramètres de complexité de chaque méthode et de comparer les formes des frontières obtenues et donc la plus ou moins bonne adéquation d'une méthode à la spécificité de ces données simulées. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Les données \n",
    "Sans passer par le format Matlab d'origine, charger les données au format texte du fichier [clouds.dat](http://www.math.univ-toulouse.fr/~besse/Wikistat/data/clouds.dat) ou les lire directement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lecture\n",
    "path=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/data/\"\n",
    "#path=\"\"\n",
    "cloud=read.table(paste(path,\"clouds.dat\",sep=\"\"))\n",
    "cloud[,1]=as.factor(cloud[,1])\n",
    "summary(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nuage de points de \"clouds\"\n",
    "plot(cloud[,2:3],col=c(\"black\", \"green\")\n",
    "     [as.integer(cloud[,1])],pch=16,cex=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Données de test\n",
    "\n",
    "Construction des données de \"test\" ou plutôt de tous les points du plan $(X, Y)$ et dont la prévision \"dessinera\" les frontières des classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testy=rep(seq(-5,5,length.out = 100),100)\n",
    "testx=sort(rep(seq(-5,5,length.out = 100),100))\n",
    "test=data.frame(\"X\"=testx,\"Y\"=testy)\n",
    "summary(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Méthodes de classification\n",
    "L'objectif est donc d'apprendre la discrimination entre les deux classes des nuages de points. L'utilisation de chaque méthode suit le méme déroulement : \n",
    "- Estimation du modéle pour une complexité donnée,\n",
    "- prévision des points du plan,\n",
    "- représentation des classes prévues dans le plan\n",
    "- méme chose pour différentes valeurs du ou des paramétres de complexité, \n",
    "- optimisation de la complexité\n",
    "- estimation et conservation de la prévision \"optimale\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Régression logistique\n",
    "Une méthode linéaire n'est évidemment pas adaptée à la forme particulière des données. D'autre part, comme seule deux variables sont concernées, la complexité ne peut être optimisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# estimation du modéle\n",
    "mod.logit=glm(classe~.,data=cloud,family=binomial)\n",
    "# prévision des points du plan\n",
    "pred.logit=predict(mod.logit,newdata=test)>0.5\n",
    "# représentation des prévisions des classes\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.logit)+1], pch = 19,cex=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Analyse discriminante par $k-nn$\n",
    "Prévision et tracés pour plusieurs valeurs de $k$ avant optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(class)\n",
    "# k \"petit\"\n",
    "prev.knn = knn(cloud[,2:3], test, cloud[,1],k=1)\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(prev.knn)],pch = 19,cex=.5,main=\"k=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k \"grand\"\n",
    "prev.knn = knn(cloud[,2:3], test, cloud[,1],k=60)\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(prev.knn)],pch = 19,cex=.5,main=\"k=60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choix k \"optimal\"\n",
    "prev.knn = knn(cloud[,2:3], test, cloud[,1],k=10)\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(prev.knn)],pch = 19,cex=.5,main=\"k=10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Détermination de $k$ \"optimal\" par validation croisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimisation de k\n",
    "library(e1071)\n",
    "plot(tune.knn(cloud[,2:3],cloud[,1],k=seq(2,50, by=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Arbre binaire de discrimination\n",
    "L'optimisation de la complexité (paramétre `cp` est opérée de façon directe comme suggérée dans la librairie `rpart`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(rpart) \n",
    "# forte pénalité\n",
    "mod.tree=rpart(classe~.,data=cloud,parms=list(split=\"information\"),cp=0.1)\n",
    "# summary(mod.tree)\n",
    "# en commentaire car trop bavarde\n",
    "# Tracé de l'arbre \n",
    "library(partykit) # si java est bien installé\n",
    "plot(as.party(mod.tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred.tree=predict(mod.tree,newdata=test,type=\"class\")\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.tree)], pch = 19,cex=.5,main=\"CP=0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pénalité nulle\n",
    "mod.tree=rpart(classe~.,data=cloud,parms=list(split=\"information\"),cp=0)\n",
    "pred.tree=predict(mod.tree,newdata=test,type=\"class\")\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.tree)], pch = 19,cex=.5,main=\"CP=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(as.party(mod.tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"optimisation\" de cp par validation croisée\n",
    "xmat = xpred.rpart(mod.tree)\n",
    "# Comparaison des valeurs prédites et observées\n",
    "xerr=as.integer(cloud[,\"classe\"])!= xmat\n",
    "# Calcul et affichage des estimations des taux d'erreur\n",
    "# apply(xerr, 2, sum)/nrow(xerr)\n",
    "# recherche du minimum\n",
    "cpopt=which.min(apply(xerr, 2, sum)/nrow(xerr))\n",
    "opt.tree=prune(mod.tree,cp=cpopt)\n",
    "pred.tree=predict(mod.tree,newdata=test,type=\"class\")\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.tree)], pch = 19,cex=.5,main=\"CP=opt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Réseaux de neurones\n",
    "Au moins deux paramétres de complexité peuvent étre considérés : le nombre de neurones et le pénalisation de type *ridge* (`decay`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(nnet)\n",
    "# sans contrainte\n",
    "mod.rn=nnet(classe~.,data=cloud,size=10,decay=0)\n",
    "pred.rn=predict(mod.rn,newdata=test,type=\"class\")\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.rn)+1], pch = 19,cex=.5,main=\"size=10 et decay=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# forte pénalisation\n",
    "mod.rn=nnet(classe~.,data=cloud,size=10,decay=5)\n",
    "pred.rn=predict(mod.rn,newdata=test,type=\"class\")\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.rn)+1], pch = 19,cex=.5,main=\"size=10 et decay=5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"optimisation\" à exécuter avec un peu de temps\n",
    "# devant soi... (retirer les ##)\n",
    "plot(tune.nnet(classe~.,data=cloud,\n",
    "    size=c(3,4,5),decay=c(0,1,2),maxit=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choix \"optimal\"\n",
    "mod.rn=nnet(classe~.,data=cloud,size=5,decay=0,maxit=200)\n",
    "pred.rn=predict(mod.rn,newdata=test,type=\"class\")\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.rn)+1], pch = 19,cex=.5,main=\"size=5 et decay=0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Agrégation de modéles\n",
    "En dimension 2, les algorithmes d'agrégation ont bien moins d'intérét d'autant que celui des foréts aléatoires ne se distingue pas du *bagging. Seul ce dernier est testé. Observer l'évolution des frontiéres avec l'accroissement du nombre d'arbres dans l'agrégation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(ipred)\n",
    "for (i in c(1,4,10,100)) {\n",
    "mod.bag=bagging(classe~.,data=cloud,nbag=i)\n",
    "pred.bag=predict(mod.bag,newdata=test,type=\"class\")\n",
    "plot(test, col=c(\"black\", \"green\")\n",
    "   [as.numeric(pred.bag)], pch = 19,cex=.5,\n",
    "   main=paste(\"N=\",as.character(i)))\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Machines à vecteurs supports\n",
    "Deux noyaux sont testés, celui linéaire simplement pour mémoire alors que celui gaussien (`radial`) fait intervenir deux paramétres: la pénalisation (`cost`) de mauvais classement et la variance (`gamma`) du noyau gaussien. Deux valeurs relativement extrémes sont testées avant de les optimiser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noyau linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "mod.svm=svm(classe~.,data=cloud,kernel=\"linear\")\n",
    "pred.svm=predict(mod.svm,newdata=test)\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.svm)], pch = 19,cex=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noyau gaussien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.svm=svm(classe~.,data=cloud,kernel=\"radial\",cost=5, gamma=1)\n",
    "pred.svm=predict(mod.svm,newdata=test)\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.svm)], pch = 19,cex=.5, main=\"cost=5 et gamma=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.svm=svm(classe~.,data=cloud,kernel=\"radial\",cost=5, gamma=0.1)\n",
    "pred.svm=predict(mod.svm,newdata=test)\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.svm)], pch = 19,cex=.5,main=\"cost=5 et gamma=0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.svm=svm(classe~.,data=cloud,kernel=\"radial\",cost=0.01, gamma=1)\n",
    "pred.svm=predict(mod.svm,newdata=test)\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.svm)], pch = 19,cex=.5,main=\"cost=0.01 et gamma=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod.svm=svm(classe~.,data=cloud,kernel=\"radial\",cost=1, gamma=0.1)\n",
    "pred.svm=predict(mod.svm,newdata=test)\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.svm)], pch = 19,cex=.5,main=\"cost=1 et gamma=0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optimisation\n",
    "# A exécuter avec un peu de temps devant soi...\n",
    "## plot(tune.svm(classe~.,data=cloud,\n",
    "##   kernel=\"radial\",cost=c(2,3,4,5,6),\n",
    "#\t gamma=c(1,0.7,0.5,0.3,0.1)))\n",
    "mod.svm=svm(classe~.,data=cloud,kernel=\"radial\",cost=4,gamma=.8)\n",
    "pred.svm=predict(mod.svm,newdata=test)\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.svm)], pch = 19,cex=.5,main=\"cost=4 et gamma=0.8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Synthèse\n",
    "A l'exception des modèles linéaires triviaux, les graphiques obtenus pour chacune des derniers \"meilleurs\" modèles pour chacune des méthodes sont représentés simultanément pour faciliter la comparaison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par(mfcol=c(2,3))\n",
    "plot(cloud[,2:3], col=c(\"black\", \"green\")[as.integer(cloud[,1])], pch = 19,cex=.1,main=\"train\")\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(prev.knn)],pch = 19,cex=.5,main=\"k-nn\")\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.tree)],pch = 19,cex=.5,main=\"tree\")\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.rn)+1],pch = 19,cex=.5,main=\"rn\")\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.bag)],pch = 19,cex=.5,main=\"bag\")\n",
    "plot(test, col=c(\"black\", \"green\")[as.numeric(pred.svm)], pch = 19,cex=.5,main=\"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
